# Danielson Framework Evaluation and Scoring Guide

## Overview
This guide provides structured approaches for using the Danielson Framework to evaluate teaching effectiveness, develop coaching plans, and facilitate collaborative scoring conversations.

## Official Performance Levels

The Danielson Framework uses four performance levels for evaluation:

### Level 1: Unsatisfactory
- **Description**: Performance is below basic expectations; practices fail to meet criteria and require immediate improvement
- **Characteristics**: 
  - Limited understanding of component expectations
  - Practices may be harmful to student learning
  - Requires intensive support and intervention
  - Focus on meeting basic professional standards

### Level 2: Basic
- **Description**: Performance meets some criteria but is inconsistent or incomplete; support is needed to reach effectiveness
- **Characteristics**:
  - Demonstrates basic understanding of component expectations
  - Inconsistent implementation or limited evidence
  - May require support to meet component standards
  - Focus on building foundational skills and consistency

### Level 3: Proficient
- **Description**: Performance consistently meets expectations; teaching is effective, learning is supported, and responsibilities are fulfilled
- **Characteristics**:
  - Consistently demonstrates component expectations
  - Clear evidence of effective practice
  - Meets professional standards reliably
  - Ready for refinement and enhancement

### Level 4: Distinguished
- **Description**: Performance is exemplary; teaching is highly skilled and reflective and serves as a model for others
- **Characteristics**:
  - Exceeds component expectations consistently
  - Serves as a model for other educators
  - Takes leadership in the component area
  - Drives innovation and school-wide improvement

## Evidence Collection Framework

### Domain 1: Planning and Preparation
**Primary Evidence Sources:**
- Lesson plans and unit designs
- Assessment designs and rubrics
- Evidence of student knowledge (surveys, data analysis)
- Resource selection and adaptation
- Curriculum alignment documentation

**Key Questions for Evaluation:**
- How does planning reflect deep content knowledge?
- What evidence shows understanding of student needs?
- Are learning objectives clear, measurable, and appropriately challenging?
- How are assessments aligned to objectives?

### Domain 2: Learning Environments
**Primary Evidence Sources:**
- Classroom observations (multiple visits)
- Student interaction patterns
- Physical environment documentation
- Conflict resolution examples
- Student voice and choice evidence

**Key Questions for Evaluation:**
- How do interactions demonstrate respect and cultural responsiveness?
- What systems support student autonomy and responsibility?
- How is the physical space organized to support learning?
- What evidence shows a positive culture for learning?

### Domain 3: Learning Experiences
**Primary Evidence Sources:**
- Lesson observations (full lessons)
- Student work samples
- Assessment data and feedback examples
- Student engagement indicators
- Evidence of responsive teaching

**Key Questions for Evaluation:**
- How clearly are purposes and expectations communicated?
- What types of questions promote critical thinking?
- How engaged are students in meaningful learning?
- How is assessment used to support learning?
- What evidence shows responsive adjustments to student needs?

### Domain 4: Principled Teaching
**Primary Evidence Sources:**
- Reflection artifacts and self-assessments
- Professional development participation
- Family communication examples
- School community contributions
- Student progress documentation

**Key Questions for Evaluation:**
- How does the teacher reflect on and improve practice?
- What evidence shows meaningful family engagement?
- How does the teacher contribute to school community?
- What demonstrates ongoing professional growth?

## Scoring Process

### Step 1: Evidence Gathering
- Collect multiple forms of evidence across time
- Use triangulation (observations, artifacts, conversations)
- Ensure cultural responsiveness in evidence interpretation
- Document specific examples rather than generalizations

### Step 2: Component Analysis
For each component:
1. **Identify Evidence**: What specific evidence relates to this component?
2. **Analyze Quality**: How well does the evidence demonstrate the component elements?
3. **Consider Context**: What contextual factors influence this evidence?
4. **Determine Level**: Which performance level best describes the overall evidence?

### Step 3: Pattern Recognition
- Look for strengths and growth areas across domains
- Identify connections between components
- Consider the teacher's overall effectiveness
- Note areas for professional development focus

### Step 4: Performance Level Determination
For each component, use the official four-level rubric:

**Level 1 - Unsatisfactory**: Evidence shows practices that fail to meet basic criteria and may be harmful to student learning. Immediate intervention required.

**Level 2 - Basic**: Evidence shows some understanding but inconsistent implementation. Performance meets some criteria but requires support to reach effectiveness.

**Level 3 - Proficient**: Evidence consistently demonstrates effective practice that meets all component expectations. Teaching supports student learning and professional responsibilities are fulfilled.

**Level 4 - Distinguished**: Evidence shows exemplary practice that exceeds expectations and serves as a model for others. Performance drives innovation and improvement.

### Step 5: Collaborative Scoring Conversation
- Share evidence interpretations
- Discuss different perspectives on performance levels
- Use the official 4-level rubric consistently
- Reach consensus through professional dialogue
- Focus on growth and improvement planning

### Pre-Observation Coaching
**Key Questions:**
- What are your learning objectives for this lesson?
- How does this lesson connect to your unit goals?
- What do you know about your students that influenced your planning?
- What are you most excited about in this lesson?
- What concerns do you have?

**Framework Connection:**
- Domain 1: Planning decisions and rationale
- Domain 2: Environment preparation and expectations
- Domain 3: Instructional strategies and assessment plans

### Post-Observation Coaching
**Reflection Protocol:**
1. **Self-Assessment**: How do you think the lesson went?
2. **Evidence Review**: What did we observe that supports student learning?
3. **Growth Areas**: What would you do differently next time?
4. **Framework Alignment**: How does this connect to the Danielson components?
5. **Next Steps**: What support or resources would be helpful?

## Coaching Conversation Framework

### Using Performance Levels in Coaching

**Level 1 (Unsatisfactory) - Intensive Support Approach:**
- Daily check-ins and support
- Clear improvement plans with specific timelines
- Modeling and co-teaching
- Focus on student safety and basic professional standards

**Level 2 (Basic) - Developmental Support Approach:**
- Weekly coaching conversations
- Skill-building professional development
- Peer observations and mentoring
- Focus on consistency and foundational practices

**Level 3 (Proficient) - Enhancement Approach:**
- Bi-weekly or monthly coaching check-ins
- Innovation and risk-taking encouraged
- Peer collaboration and leadership opportunities
- Focus on refinement and student outcome improvement

**Level 4 (Distinguished) - Leadership Development Approach:**
- As-needed consultation and support
- Mentoring and coaching other teachers
- Leading professional development
- Focus on school-wide impact and innovation

### Coaching Focus Areas by Experience Level

#### New Teachers (0-3 years)
**Priority Components:**
- 1a: Content and pedagogical knowledge
- 2a: Respectful environments  
- 3a: Clear communication
- 4a: Reflective practice

**Typical Performance Levels**: Often Level 2 (Basic), working toward Level 3 (Proficient)

**Coaching Approach:**
- High support, frequent feedback
- Modeling and co-teaching opportunities
- Focus on essential practices
- Build confidence through strengths

#### Developing Teachers (4-10 years)
**Priority Components:**
- 1b: Knowing students deeply
- 2b: Culture for learning
- 3b: Questioning techniques
- 4e: Professional growth

**Typical Performance Levels**: Solid Level 3 (Proficient), some areas approaching Level 4 (Distinguished)

**Coaching Approach:**
- Collaborative planning and reflection
- Peer observations and sharing
- Action research projects
- Leadership opportunities

#### Experienced Teachers (10+ years)
**Priority Components:**
- 1c: Ambitious learning outcomes
- 2d: Student self-regulation
- 3e: Responsive teaching
- 4d: School community leadership

**Typical Performance Levels**: Consistent Level 3 (Proficient) with multiple Level 4 (Distinguished) areas

**Coaching Approach:**
- Peer coaching and mentoring
- Innovation and risk-taking
- School-wide leadership roles
- Student outcome focus

## Collaborative Scoring Protocol

### Phase 1: Individual Preparation
- Review all available evidence
- Complete initial component ratings
- Identify key evidence for each rating
- Note questions or areas of uncertainty

### Phase 2: Evidence Sharing
- Present evidence without ratings
- Ask clarifying questions
- Ensure all participants understand the context
- Identify additional evidence needs

### Phase 3: Component Discussion
- Discuss each component systematically
- Share individual ratings and rationales
- Explore different interpretations
- Seek consensus through professional dialogue

### Phase 4: Growth Planning
- Identify 2-3 priority growth areas
- Connect to school/district goals
- Plan support and resources
- Set timeline for progress monitoring

## Common Scoring Considerations

### Avoid These Pitfalls:
- Rating based on personality rather than practice
- Using insufficient evidence
- Comparing teachers to each other rather than standards
- Focusing only on deficits rather than growth
- Ignoring cultural and contextual factors

### Ensure These Practices:
- Multiple observations across different contexts
- Triangulation of evidence sources
- Cultural responsiveness in interpretation
- Growth-oriented conversations
- Clear connections between evidence and ratings
- Actionable feedback and support plans

## Documentation Best Practices

### Evidence Collection:
- Date and context all observations
- Use objective, descriptive language
- Include student voice and perspective
- Document positive examples alongside growth areas
- Maintain confidentiality and professionalism

### Scoring Records:
- Provide specific evidence for each component rating
- Include contextual factors that influenced performance
- Document professional development needs and plans
- Track growth over time
- Maintain clear, organized records